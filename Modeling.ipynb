{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "\n",
        "Spencer Brothers\n",
        "\n",
        "The next step is to explore different modeling ideas for the project, with the aim of developing a model that beats a benchmark model (such as the majority class classifier) and produces results that -- hopefully! -- can be used to solve the business problem.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "- Practice feature engineering to improve model performance.\n",
        "\n",
        "- Practice cross-validation.\n",
        "\n",
        "- Learn about the properties of different modeling algorithms by experimenting with different methods and comparing different candidate models.\n",
        "\n",
        "- Learn from your group members.\n",
        "\n",
        "## Tasks\n",
        "\n",
        "- Set up a training set and a validation set using application_train.csv data set to do cross-validation.  Alternatively you could perform cross-validation using a different framework, such as k-fold cross validation as implemented in modeling packages such as caret or tidymodels or scikit-learn. The model performance that matters, of course, is the estimated performance on the test set as well as the Kaggle score.\n",
        "\n",
        "- Identify the performance benchmark established by the majority class classifier.\n",
        "\n",
        "- Fit several different logistic regression models using different predictors. Do interaction terms improve the model?  Compare model performance using not just accuracy but also AUC.\n",
        "Explore using algorithms like random forest and gradient boosting. Compare model performance.\n",
        "\n",
        "- Perform the data transformations required by a given algorithm.  For example, some algorithms require numeric data and perform better when it has been standardized or normalized.\n",
        "Experiment with upsampling and downsampling the data to adjust for the imbalanced target variable.  (See APM Ch. 16.)  Does this strategy this improve model performance?\n",
        "\n",
        "- Try combining model predictions--this is called an ensemble model--to improve performance.\n",
        "\n",
        "- Try additional feature engineering to boost model performance. Can you combine variables or bin numeric variables?  Explore the notebooks at Kaggle for data transformation ideas. In particular, use the other data sets at Kaggle--beyond the application data--to create additional features.\n",
        "\n",
        "- For machine learning models experiment with hyperparameter tuning  to try to boost performance.\n"
      ],
      "metadata": {
        "id": "AIDyCwD89nwQ"
      },
      "id": "AIDyCwD89nwQ"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(f'Number of CPUs: {os.cpu_count()}')"
      ],
      "metadata": {
        "id": "Xi8MHvpP0RJ7",
        "outputId": "80c7f1ea-c754-4e67-b868-1a6429ff1960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Xi8MHvpP0RJ7",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of CPUs: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sJul4r_Z066j"
      },
      "id": "sJul4r_Z066j"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}